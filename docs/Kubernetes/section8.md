# Section8 - Storage

- [Docker Storage](#Docker-Storage)  
- [Container Storage Interface](#Container-Storage-Interface)  
- [Persistent Volumes](#Persistent-Volumes)  
- [Storage Class](#Storage-Class)  

## Docker Storage
- When it comes to storage in Docker, there are two concepts.
    - Storage drivers
    - Volume drivers

### Filesystem

- Let's see how Docker stores data on the local file system. At the first time, When you install Docker on a system, it creates this directory structures at /var/lib/docker.

  ```console
  $ cd /var/lib/docker/
  ```

  ![File system](https://github.com/kodekloudhub/certified-kubernetes-administrator-course/blob/master/images/class2.PNG)


- Docker - image - container

![image](https://github.com/kodekloudhub/certified-kubernetes-administrator-course/blob/master/images/class6.PNG)

  - When you run a container based off of the image with image layers, using the **Docker run** command Docker creates a container based off of these layers and creates a new writeable layer on top of the image layer. 
  - The writeable layer is used to store data created by the container such as log files written by the applications, any temporary files generated by the container.
  - The life of Container layer though is only as long as the container is alive. When the container is destroyed, this layer and all of the changes stored in it are also destroyed.
  - **Remember that the same image layer is shared by all containers created using this image.**

- Update image layer data as a copy-on-write

![dd](https://github.com/kodekloudhub/certified-kubernetes-administrator-course/blob/master/images/class7.PNG)

  - Let's take an example of our application code. Since we bake our code into the image, the code is part of the image and as such, its read-only. After running a container, what if I wish to modify the source code.
  - Yes, I can still modify this file, but before I saved the modified file, Docker automatically creates a copy of the file in the read-write layer and I will then be modifying a different version of the file in the read-write layer. All future modifications will be done on this copy of the file in the read-write layer. This is called **copy-on-write** mechanism.
  - The Image layer being a read-only just means that the files in these layers will not be modified in the image itself. So, the image will remain the same all the time until you rebuild the image using the Docker build command. **If container destroyed then all of the data that was stored in the container layer also gets deleted.**


- So what if we wish to persist this data?
  - we could add a **persistent volume** to the container.
  - To do this first create a volume using the docker volume create command.
  - So when I run the docker volume create data underscore volume command, it creates a folder called data underscore volume under the VAR lib docker volumes directory.
  - Then when I run the docker container using the `docker run` command, I could mount this volume inside the docker containers rewrite layer using the dash V option like this.
  
  ![mount](https://github.com/kodekloudhub/certified-kubernetes-administrator-course/blob/master/images/class8.PNG)
  
  - This will create a new container and mount the data volume we created into VAR lib mysql folder inside the container. So all data written by the database is in fact stored on the volume created on the Docker host.

- You should be able to see all these volumes if you list the contents of the `/var/lib/docker` volumes directory. This is called **Volume mounting**.
- What if we had our data already at another location?
- Let's say we have some external storage on the Docker host at `/data` path and we would like to store database data on that volume and not in the default `/var/lib/docker` volumes directory. In that case, we would run a container using the command `docker run -v`. But in this case, we will provide the complete path to the directory we would like to mount. That is `/data/mysql` and so it will create a container and mount the directory to the container. This is called **Bind mounting**.
- So there are two types of mounts, volume mount and bind mount.
  * Volume mount, mounts of volume from the volumes directory and bind mount, mounts indirectly from any location on the Docker host.
- Instead of `-v` option, we can preferred `--mount` option.

  ```
  $ mkdir -p /data/mysql
  $ docker run --mount type=bind,source=/data/mysql,target=/var/lib/mysql mysql
  ```
- So, who is responsible for doing all of these Operations? 
- Maintaining of layered architecture, creating a writeable layer, moving files across layers to enable copy and write etc. It's the **Storage Drivers**.
- Docker uses storage drivers to enable layered architecture.

#### Common Storage Drivers

- AUFS
- ZFS
- BTRFS
- Device Mapper
- Overlay
- Overlay2

- To Selection of the storage drivers depends on the underlying OS. Docker will choose the best storage driver available automatically based on the operating system.

#### Docker References

- https://docs.docker.com/storage/
- https://docs.docker.com/engine/reference/commandline/volume_create/
- https://docs.docker.com/engine/reference/commandline/volume_ls/


## Container Storage Interface

![cc](https://github.com/kodekloudhub/certified-kubernetes-administrator-course/blob/master/images/class13.PNG)

### Container Runtime Interface

- Kubernetes used Docker alone as the container runtime engine, and all the code to work with Docker was embedded within the Kubernetes source code. Other container runtimes, such as rkt and CRI-O.
- The Container Runtime Interface is a standard that defines how an orchestration solution like Kubernetes would communicate with container runtimes like Docker. If any new container runtime interace is developed, they can simply follow the CRI standards.

### Container Networking Interface

- To support different networking solutions, the container networking interface was introduced. Any new networking vendors could simply develop their plugin based on the CNI standards and make their solution work with Kubernetes.

### Container Storage Interface

- The container storage interface was developed to support multiple storage solutions. With CSI, you can now write your own drivers for your own storage to work with Kubernetes. Portworx, Amazon EBS, Azure Disk, GlusterFS etc.
- CSI is not a Kubernetes specific standard. It is meant to be a universal standard and if implemented, allows any container orchestration tool to work with any storage vendor with a supported plugin. Kubernetes, Cloud Foundry and Mesos are onboard with CSI.
- It defines a set of RPCs or remote procedure calls that will be called by the container orchestrator. These must be implemented by the storage drivers.

## Persistent Volumes

### Volumes
- We discussed about Docker storage, If we don't attach the volume in the container runtime, when container destroyed and then all data will be lost. So, *We need to persist data into the Docker container* so we attach a volume to the containers when they are created.

- The data are processed by the container is now placed in this volume thereby retaining it permanently. Even if the container is deleted the data remains in the volume.

- In the Kubernetes world, the PODs created in Kubernetes are transient in nature. When a POD is created to process data and then deleted, the data processed by it gets deleted as well. 

![volumes](https://github.com/kodekloudhub/certified-kubernetes-administrator-course/blob/master/images/class14.PNG)

- For example, We create a simple POD that generated a random between 1 and 100 and writes that to a file at `/opt/number.out`. To persist into the volume.
- We create a volume for that. In this case I specify a path `/data` on the host. Files are stored in the directory data on my node. We use the **volumeMounts** field in each container to mount the data-volume to the directory `/opt` within the container. The random number will now be written to `/opt` mount inside the container, which happens to be on the data-volume which is in fact `/data` directory on the host. When the pod gets deleted, the file with the random number still lives on the host.

### Volume Storage Options
![Volume types](https://github.com/kodekloudhub/certified-kubernetes-administrator-course/blob/master/images/class15.PNG)

- **In the volumes, hostPath volume type is fine with the single node. It's not recomended for use with the multi node cluster.**

- In the Kubernetes, it supports several types of standard storage solutions such as NFS, GlusterFS, CephFS or public cloud solutions like AWS EBS, Azure Disk or Google's Persistent Disk.

### Persistent Volumes

- **A Persistent Volume is a cluster-wide pool of storage volumes configured by an administrator** to be used by users deploying application on the cluster. The users can now select storage from this pool using **Persistent Volume Claims**.

  ```yaml
  pv-definition.yaml
  
  kind: PersistentVolume
  apiVersion: v1
  metadata:
    name: pv-vol1
  spec:
    accessModes: [ "ReadWriteOnce" ] 
    capacity:
     storage: 1Gi
    hostPath:
     path: /tmp/data
  ```

  -  `accessModes` defines how a volume should be mounted on the hosts, whether in a read-only mode or read/write mode, etc.
    - ReadOnlyMany
    - ReadWriteOnce
    - ReadWriteMany

  - `capacity`
    - Specify the amount of storage to be reserved for this persistent volume

  - `hostPath`
    - Volume type 
    - In the above example, it uses storage from the node's local directory

### Create & Delete the volume

  ```console
  $ kubectl create -f pv-definition.yaml
  persistentvolume/pv-vol1 created
  $ kubectl get pv
  NAME      CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS      CLAIM   STORAGECLASS   REASON   AGE
  pv-vol1   1Gi        RWO            Retain           Available                                   3min
  
  $ kubectl delete pv pv-vol1
  persistentvolume "pv-vol1" deleted
  ```

### Persistent Volume Claim
- Persistent Volumes and Persistent Volume Claims are two separate objects in the Kubernetes name space.

  - An administrator creates a set of **persistent volumes**
  - A user creates **persistent volume claims** to use the storage.

- Once the persistent volume claims are created, Kubernetes binds the persistent volumes to claims based on the request and properties set on the volume.

- If you would like to specifically use a particular volume
  - use **labels and selectors** 

- If properties not matches or Persistent Volume is not available for the Persistent Volume Claim then it will display the pending state.

```yaml
pvc-definition.yaml
kind: PersistentVolumeClaim
apiVersion: v1
metadata:
  name: myclaim
spec:
  accessModes: [ "ReadWriteOnce" ]
  resources:
   requests:
     storage: 1Gi
```


#### Create the Persistent Volume Claim

```console
$ kubectl create -f pvc-definition.yaml
persistentvolumeclaim/myclaim created
$ kubectl get pvc
NAME      STATUS    VOLUME   CAPACITY   ACCESS MODES   STORAGECLASS   AGE
myclaim   Pending                                                     35s
$ kubectl get pvc
NAME      STATUS   VOLUME    CAPACITY   ACCESS MODES   STORAGECLASS   AGE
myclaim   Bound    pv-vol1   1Gi        RWO                           1min
```

#### Delete the Persistent Volume Claim

```console
$ kubectl delete pvc myclaim
```


### Practice

- Configure a volume to store these logs at /var/log/webapp on the host.
  - https://kubernetes.io/docs/concepts/storage/volumes/

  - Name: webapp
  - Image Name: kodekloud/event-simulator
  - Volume HostPath: /var/log/webapp
  - Volume Mount: /log

  <details>
  <summary>Answer</summary>

  ```console
  ~# k edit pod webapp
  ```

  - Edit `volumes` with new hostPath and to mount volumes, Edit `volumeMounts`

  ```yaml
  volumeMounts:
  - mountPath: /log
    name: log-volume

  volumes:
  - name: log-volume
    hostPath:
      path: /var/log/webapp
  ```

  ```console
  ~# k replace --force -f /tmp/...
  ```

  </details>

- Create a Persistent Volume 
  - https://kubernetes.io/docs/concepts/storage/persistent-volumes/#persistent-volumes

  <details>
  <summary>Answer</summary>

  ```console
  ~# vi pv.yaml
  ```

  ```yaml
  apiVersion: v1
  kind: PersistentVolume
  metadata:
    name: pv-log
  spec:
    capacity:
      storage: 100Mi
    accessModes:
      - ReadWriteMany
    persistentVolumeReclaimPolicy: Retain
    hostPath:
      path: /pv/log
  ```
  
  ```console
  ~# k create -f pv.yaml
  ```

  </details>


- Let us claim some of that storage for our application. Create a Persistent Volume Claim

  - https://kubernetes.io/docs/concepts/storage/persistent-volumes/#persistentvolumeclaims
  - https://kubernetes.io/docs/tasks/configure-pod-container/configure-persistent-volume-storage/#create-a-persistentvolumeclaim


  <details>
  <summary>Answer</summary>

  ```console
  ~# vi pvc.yaml
  ```

  ```yaml
  apiVersion: v1
  kind: PersistentVolumeClaim
  metadata:
    name: claim-log-1
  spec:
    accessModes:
      - ReadWriteMany
    resources:
      requests:
        storage: 50Mi
  ```
  
    
  ```console
  ~# k create -f pvc.yaml
  ```

  </details>

-  Update the webapp pod to use the persistent volume claim as its storage.

    - Replace hostPath configured earlier with the newly created PersistentVolumeClaim.
    - https://kubernetes.io/docs/concepts/storage/persistent-volumes/#claims-as-volumes
      - `persistentVolumeClaim`

      <details>
      <summary>Answer</summary>

      ```console
      ~# k edit pod webapp
      ```

      - Edit `volumes` with persistentVolumeClaim

      ```yaml
      volumes:
      - name: log-volume
        persistentVolumeClaim:
            claimName: claim-log-1
      ```

      ```console
      ~# k replace --force -f /tmp/...
      ```
      
      </details>

- What would happen to the PV if the PVC was destroyed?
  - The PV is note deleted but not available

- Try deleting the PVC and notice what happens.
  - The PVC is stuck in *terminating* state because it is being used by a POD
  - PCV is deleted when you delete the POD
  - Then, PV is in the state of *RELEASED*


## Storage Class

- With *storage classes**, you can define a provisioner, such as Google Storage, that can automatically provision storage on Google Cloud

### Dynamic Provisioning

![dp](https://github.com/kodekloudhub/certified-kubernetes-administrator-course/blob/master/images/class19.PNG)

- so we no longer need the PV definition, because the PV and any associated storage is going to be created automatically when the storage class is created.

### Practice

> https://kubernetes.io/docs/concepts/storage/storage-classes/


- How many StorageClasses exist in the cluster right now?

  <details>
  <summary>Answer</summary>

  ```console
  ~# k get storageclass
  ~# k get sc
  NAME                   PROVISIONER             RECLAIMPOLICY   VOLUMEBINDINGMODE      ALLOWVOLUMEEXPANSION   AGE
  local-path (default)   rancher.io/local-path   Delete          WaitForFirstConsumer   false                  21m
  ~# k describe sc [STORAGE CLASS NAME]
  ``` 
  
  </details>

- Create a new pod called `nginx` with the image `nginx:alpine`. The Pod should make use of the PVC `local-pvc` and mount the volume at the path `/var/www/html`. The PV `local-pv` should in a bound state.

  <details>
  <summary>Answer</summary>

  ```console
  ~# k run nginx --imag-nginx:alpine --dry-run=client -o yaml > nginx.yaml
  ```

  - https://kubernetes.io/docs/concepts/storage/persistent-volumes/#claims-as-volumes

  ```yaml
  apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: null
    labels:
      run: nginx
    name: nginx
  spec:
    containers:
    - image: nginx
      name: nginx
      resources: {}
      volumeMounts:
      - mountPath: "/var/www/html"
        name: local-pvc-volume ## SHOULD be matched with volumes' name
    dnsPolicy: ClusterFirst
    restartPolicy: Always
    volumes:
      - name: local-pvc-volume
        persistentVolumeClaim:
          claimName: local-pvc
  status: {}
  ```
  
  ```console
  ~# k create -f nginx.yaml
  ```

  </details>

- Create a new Storage Class called *delayed-volume-sc* 

  <details>
  <summary>Answer</summary>

  - https://kubernetes.io/docs/concepts/storage/storage-classes/#the-storageclass-resource

  ```console
  ~# vi delayed-volume-sc.yaml
  ``` 

  ```yaml
  apiVersion: storage.k8s.io/v1
  kind: StorageClass
  metadata:
    name: delayed-volume-sc
  provisioner: kubernetes.io/no-provisioner
  volumeBindMode: WaitForFirstConsumer
  ```
  
  ```console
  ~# k create -f delayed-volume-sc.yaml
  ``` 

  </details>